{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "838299db-b6b5-4872-a6dc-fdfe166cbfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING NVDA PREDICTOR MODEL\n",
      "================================================================================\n",
      "\n",
      "📥 Loading models...\n",
      "✓ LSTM-GRU model loaded\n",
      "✓ LSTM scaler loaded\n",
      "✓ XGBoost model loaded\n",
      "✓ ARIMA-GARCH data loaded\n",
      "✓ LSTM metadata loaded\n",
      "✓ XGBoost metadata loaded\n",
      "✓ Configuration loaded\n",
      "✓ Last predictions loaded\n",
      "✓ Confidence intervals loaded\n",
      "✓ Risk metrics loaded\n",
      "\n",
      "✅ All models loaded successfully!\n",
      "Model saved on: 2025-10-12T22:57:31.694146\n",
      "Last data date: 2025-10-10\n",
      "\n",
      "================================================================================\n",
      "MAKING NEW PREDICTIONS\n",
      "================================================================================\n",
      "\n",
      "🔧 Engineering features...\n",
      "Latest data date: 2025-10-10\n",
      "Current Price: $183.16\n",
      "\n",
      "📊 Model Predictions:\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000132BE56B430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "  LSTM-GRU: $191.04 (+4.30%)\n",
      "  XGBoost: $182.54 (-0.34%)\n",
      "  ARIMA-GARCH: $183.28 (+0.07%)\n",
      "  Monte Carlo: $183.05 (-0.06%)\n",
      "\n",
      "  🎯 ENSEMBLE: $186.58 (+1.87%)\n",
      "\n",
      "Last Saved Prediction:\n",
      "  Date: 2025-10-10\n",
      "  Price: $183.16\n",
      "  Target: $186.58\n",
      "\n",
      "================================================================================\n",
      "CONFIDENCE INTERVALS (from saved model)\n",
      "================================================================================\n",
      "95% CI: [$182.07, $184.05]\n",
      "75% CI: [$182.65, $183.46]\n",
      "Median: $183.05\n",
      "\n",
      "================================================================================\n",
      "RISK METRICS (from saved model)\n",
      "================================================================================\n",
      "Expected Return: 1.87%\n",
      "VaR (95%): -0.60%\n",
      "CVaR (95%): -0.73%\n",
      "Sharpe Ratio: 6.79\n",
      "Volatility: 4.36%\n",
      "\n",
      "================================================================================\n",
      "TRADING SIGNAL\n",
      "================================================================================\n",
      "\n",
      "Signal: 🟢 BUY\n",
      "Action: Consider moderate entry\n",
      "Target: $186.58\n",
      "Expected Change: +1.87%\n",
      "Stop Loss: $182.07\n",
      "\n",
      "✅ Results saved to: prediction_history.csv\n",
      "✅ Latest prediction saved to: latest_prediction.json\n",
      "\n",
      "================================================================================\n",
      "PREDICTION COMPLETE!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# LOAD SAVED MODEL & MAKE PREDICTIONS \n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.models import load_model\n",
    "import xgboost as xgb\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LOADING NVDA PREDICTOR MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "model_path = Path('nvda_models/nvda_predictor_nextday_v1')\n",
    "\n",
    "def engineer_features(data):\n",
    "    \"\"\"Engineer all features for prediction\"\"\"\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Returns and volatility\n",
    "    df['Returns'] = df['Close'].pct_change()\n",
    "    df['Log_Returns'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "    df['Volatility_20'] = df['Returns'].rolling(20).std()\n",
    "    df['Volatility_60'] = df['Returns'].rolling(60).std()\n",
    "    \n",
    "    # Volume ratios\n",
    "    df['Volume_Ratio'] = df['Volume'] / df['Volume'].rolling(20).mean()\n",
    "    df['Dollar_Volume'] = df['Close'] * df['Volume']\n",
    "    \n",
    "    # Price spreads\n",
    "    df['HL_Spread'] = (df['High'] - df['Low']) / df['Close']\n",
    "    df['CO_Spread'] = (df['Close'] - df['Open']) / df['Open']\n",
    "    \n",
    "    # Rate of change\n",
    "    df['ROC_10'] = (df['Close'] - df['Close'].shift(10)) / df['Close'].shift(10)\n",
    "    df['ROC_30'] = (df['Close'] - df['Close'].shift(30)) / df['Close'].shift(30)\n",
    "    \n",
    "    # Support/Resistance\n",
    "    df['Resistance'] = df['High'].rolling(20).max()\n",
    "    df['Support'] = df['Low'].rolling(20).min()\n",
    "    df['SR_Position'] = (df['Close'] - df['Support']) / (df['Resistance'] - df['Support'])\n",
    "    \n",
    "    # Trade sizes and trends\n",
    "    df['Avg_Trade_Size'] = df['Dollar_Volume'] / df['Volume']\n",
    "    \n",
    "    # Handle missing SMA values\n",
    "    if 'SMA5' not in df.columns:\n",
    "        df['SMA5'] = df['Close'].rolling(5).mean()\n",
    "    if 'SMA50' not in df.columns:\n",
    "        df['SMA50'] = df['Close'].rolling(50).mean()\n",
    "    if 'RSI' not in df.columns:\n",
    "        delta = df['Close'].diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "        rs = gain / loss\n",
    "        df['RSI'] = 100 - (100 / (1 + rs))\n",
    "    if 'MACD' not in df.columns:\n",
    "        ema12 = df['Close'].ewm(span=12).mean()\n",
    "        ema26 = df['Close'].ewm(span=26).mean()\n",
    "        df['MACD'] = ema12 - ema26\n",
    "    if 'SMA_20' not in df.columns:\n",
    "        df['SMA_20'] = df['Close'].rolling(20).mean()\n",
    "    if 'EMA_50' not in df.columns:\n",
    "        df['EMA_50'] = df['Close'].ewm(span=50).mean()\n",
    "    if 'BB_upper' not in df.columns:\n",
    "        bb_middle = df['Close'].rolling(20).mean()\n",
    "        bb_std = df['Close'].rolling(20).std()\n",
    "        df['BB_upper'] = bb_middle + 2 * bb_std\n",
    "        df['BB_lower'] = bb_middle - 2 * bb_std\n",
    "    \n",
    "    df['Trend_Strength'] = abs(df['SMA5'] - df['SMA50']) / df['SMA50']\n",
    "    df['Volatility_Regime'] = df['Volatility_20'] / df['Volatility_60']\n",
    "    df['Price_Change'] = df['Close'].pct_change()\n",
    "    \n",
    "    return df.fillna(0)\n",
    "\n",
    "try:\n",
    "    # Load LSTM model\n",
    "    print(\"\\n📥 Loading models...\")\n",
    "    lstm_model = load_model(str(model_path / 'lstm_gru_model.h5'))\n",
    "    print(\"✓ LSTM-GRU model loaded\")\n",
    "    \n",
    "    # Load LSTM scaler\n",
    "    with open(model_path / 'lstm_scaler.pkl', 'rb') as f:\n",
    "        lstm_scaler = pickle.load(f)\n",
    "    print(\"✓ LSTM scaler loaded\")\n",
    "    \n",
    "    # Load XGBoost model\n",
    "    xgb_model = xgb.XGBRegressor()\n",
    "    xgb_model.load_model(str(model_path / 'xgboost_model.json'))\n",
    "    print(\"✓ XGBoost model loaded\")\n",
    "    \n",
    "    # Load ARIMA-GARCH data\n",
    "    with open(model_path / 'arima_garch_data.pkl', 'rb') as f:\n",
    "        arima_garch_data = pickle.load(f)\n",
    "    print(\"✓ ARIMA-GARCH data loaded\")\n",
    "    \n",
    "    # Load metadata\n",
    "    with open(model_path / 'lstm_metadata.json', 'r') as f:\n",
    "        lstm_metadata = json.load(f)\n",
    "    print(\"✓ LSTM metadata loaded\")\n",
    "    \n",
    "    with open(model_path / 'xgboost_metadata.pkl', 'rb') as f:\n",
    "        xgb_metadata = pickle.load(f)\n",
    "    print(\"✓ XGBoost metadata loaded\")\n",
    "    \n",
    "    # Load config\n",
    "    with open(model_path / 'config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "    print(\"✓ Configuration loaded\")\n",
    "    \n",
    "    # Load last predictions\n",
    "    with open(model_path / 'predictions.json', 'r') as f:\n",
    "        last_predictions = json.load(f)\n",
    "    print(\"✓ Last predictions loaded\")\n",
    "    \n",
    "    # Load confidence intervals\n",
    "    with open(model_path / 'confidence_intervals.json', 'r') as f:\n",
    "        confidence_intervals = json.load(f)\n",
    "    print(\"✓ Confidence intervals loaded\")\n",
    "    \n",
    "    # Load risk metrics\n",
    "    with open(model_path / 'risk_metrics.json', 'r') as f:\n",
    "        risk_metrics = json.load(f)\n",
    "    print(\"✓ Risk metrics loaded\")\n",
    "    \n",
    "    print(\"\\n✅ All models loaded successfully!\")\n",
    "    print(f\"Model saved on: {config['saved_date']}\")\n",
    "    print(f\"Last data date: {config['last_data_date']}\")\n",
    "    \n",
    "    # ========== MAKE NEW PREDICTIONS ==========\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MAKING NEW PREDICTIONS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Load and engineer features\n",
    "    print(\"\\n🔧 Engineering features...\")\n",
    "    df = pd.read_csv('NVDA_dataset_updated.csv')\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.set_index('date', inplace=True)\n",
    "    df = df.sort_index()\n",
    "    \n",
    "    df = engineer_features(df)\n",
    "    \n",
    "    print(f\"Latest data date: {df.index[-1].strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    current_price = df['Close'].iloc[-1]\n",
    "    print(f\"Current Price: ${current_price:.2f}\")\n",
    "    \n",
    "    # 1. LSTM-GRU prediction\n",
    "    print(\"\\n📊 Model Predictions:\")\n",
    "    seq_len = lstm_metadata['sequence_length']\n",
    "    feature_cols = lstm_metadata['feature_cols']\n",
    "    close_idx = lstm_metadata['close_idx']\n",
    "    \n",
    "    last_sequence = df[feature_cols].iloc[-seq_len:].fillna(0).values\n",
    "    last_sequence_scaled = lstm_scaler.transform(last_sequence)\n",
    "    last_sequence_scaled = last_sequence_scaled.reshape(1, seq_len, -1)\n",
    "    \n",
    "    lstm_pred_scaled = lstm_model.predict(last_sequence_scaled, verbose=0)[0, 0]\n",
    "    close_min = lstm_scaler.data_min_[close_idx]\n",
    "    close_range = lstm_scaler.data_range_[close_idx]\n",
    "    lstm_pred = float(lstm_pred_scaled * close_range + close_min)\n",
    "    \n",
    "    print(f\"  LSTM-GRU: ${lstm_pred:.2f} ({(lstm_pred/current_price - 1)*100:+.2f}%)\")\n",
    "    \n",
    "    # 2. XGBoost prediction\n",
    "    xgb_features = xgb_metadata['features']\n",
    "    last_features = df[xgb_features].iloc[-1].fillna(0).values.reshape(1, -1)\n",
    "    xgb_change = float(xgb_model.predict(last_features)[0])\n",
    "    xgb_pred = current_price * (1 + xgb_change)\n",
    "    \n",
    "    print(f\"  XGBoost: ${xgb_pred:.2f} ({(xgb_pred/current_price - 1)*100:+.2f}%)\")\n",
    "    \n",
    "    # 3. ARIMA-GARCH prediction - FIXED: Convert to float\n",
    "    arima_forecast = arima_garch_data['forecast_mean']\n",
    "    if isinstance(arima_forecast, np.ndarray):\n",
    "        arima_forecast = float(arima_forecast[0])\n",
    "    else:\n",
    "        arima_forecast = float(arima_forecast)\n",
    "    \n",
    "    arima_pred = current_price * np.exp(arima_forecast)\n",
    "    print(f\"  ARIMA-GARCH: ${arima_pred:.2f} ({(arima_pred/current_price - 1)*100:+.2f}%)\")\n",
    "    \n",
    "    # 4. Monte Carlo median (from saved data)\n",
    "    mc_median = confidence_intervals['median']\n",
    "    print(f\"  Monte Carlo: ${mc_median:.2f} ({(mc_median/current_price - 1)*100:+.2f}%)\")\n",
    "    \n",
    "    # 5. Ensemble prediction using saved weights\n",
    "    weights = config['ensemble_weights']\n",
    "    ensemble = (\n",
    "        weights['ARIMA-GARCH'] * arima_pred +\n",
    "        weights['XGBoost'] * xgb_pred +\n",
    "        weights['LSTM-GRU'] * lstm_pred +\n",
    "        weights['Monte_Carlo'] * mc_median\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n  🎯 ENSEMBLE: ${ensemble:.2f} ({(ensemble/current_price - 1)*100:+.2f}%)\")\n",
    "    \n",
    "    # 6. Compare with last saved prediction\n",
    "    print(f\"\\nLast Saved Prediction:\")\n",
    "    print(f\"  Date: {config['last_data_date']}\")\n",
    "    print(f\"  Price: ${last_predictions['current_price']:.2f}\")\n",
    "    print(f\"  Target: ${last_predictions['ensemble']:.2f}\")\n",
    "    \n",
    "    # ========== CONFIDENCE INTERVALS ==========\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CONFIDENCE INTERVALS (from saved model)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"95% CI: [${confidence_intervals['lower_95']:.2f}, ${confidence_intervals['upper_95']:.2f}]\")\n",
    "    print(f\"75% CI: [${confidence_intervals['lower_75']:.2f}, ${confidence_intervals['upper_75']:.2f}]\")\n",
    "    print(f\"Median: ${confidence_intervals['median']:.2f}\")\n",
    "    \n",
    "    # ========== RISK METRICS ==========\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RISK METRICS (from saved model)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Expected Return: {risk_metrics['expected_return']:.2f}%\")\n",
    "    print(f\"VaR (95%): {risk_metrics['VaR_95']:.2f}%\")\n",
    "    print(f\"CVaR (95%): {risk_metrics['CVaR_95']:.2f}%\")\n",
    "    print(f\"Sharpe Ratio: {risk_metrics['sharpe_ratio']:.2f}\")\n",
    "    print(f\"Volatility: {risk_metrics['volatility_forecast']:.2f}%\")\n",
    "    \n",
    "    # ========== TRADING SIGNAL ==========\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TRADING SIGNAL\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    change = (ensemble / current_price - 1) * 100\n",
    "    \n",
    "    if change > 2:\n",
    "        signal = \"🟢 STRONG BUY\"\n",
    "        action = \"Consider aggressive entry\"\n",
    "    elif change > 0.5:\n",
    "        signal = \"🟢 BUY\"\n",
    "        action = \"Consider moderate entry\"\n",
    "    elif change < -2:\n",
    "        signal = \"🔴 STRONG SELL\"\n",
    "        action = \"Consider exit or short\"\n",
    "    elif change < -0.5:\n",
    "        signal = \"🔴 SELL\"\n",
    "        action = \"Consider reducing position\"\n",
    "    else:\n",
    "        signal = \"🟡 HOLD\"\n",
    "        action = \"Wait for better setup\"\n",
    "    \n",
    "    print(f\"\\nSignal: {signal}\")\n",
    "    print(f\"Action: {action}\")\n",
    "    print(f\"Target: ${ensemble:.2f}\")\n",
    "    print(f\"Expected Change: {change:+.2f}%\")\n",
    "    print(f\"Stop Loss: ${current_price * (1 + risk_metrics['VaR_95']/100):.2f}\")\n",
    "    \n",
    "    # ========== SAVE RESULTS ==========\n",
    "    results_df = pd.DataFrame({\n",
    "        'Timestamp': [pd.Timestamp.now()],\n",
    "        'Data_Date': [df.index[-1].strftime('%Y-%m-%d')],\n",
    "        'Current_Price': [current_price],\n",
    "        'LSTM_Pred': [lstm_pred],\n",
    "        'XGBoost_Pred': [xgb_pred],\n",
    "        'ARIMA_Pred': [arima_pred],\n",
    "        'MC_Median': [mc_median],\n",
    "        'Ensemble': [ensemble],\n",
    "        'Change_%': [change],\n",
    "        'Signal': [signal],\n",
    "        'Lower_95CI': [confidence_intervals['lower_95']],\n",
    "        'Upper_95CI': [confidence_intervals['upper_95']],\n",
    "        'Sharpe_Ratio': [risk_metrics['sharpe_ratio']]\n",
    "    })\n",
    "    \n",
    "    # Append to history\n",
    "    history_file = 'prediction_history.csv'\n",
    "    if Path(history_file).exists():\n",
    "        history_df = pd.read_csv(history_file)\n",
    "        results_df = pd.concat([history_df, results_df], ignore_index=True)\n",
    "    \n",
    "    results_df.to_csv(history_file, index=False)\n",
    "    print(f\"\\n✅ Results saved to: {history_file}\")\n",
    "    \n",
    "    # Save latest prediction\n",
    "    latest_pred = {\n",
    "        'timestamp': pd.Timestamp.now().isoformat(),\n",
    "        'data_date': df.index[-1].strftime('%Y-%m-%d'),\n",
    "        'current_price': float(current_price),\n",
    "        'predictions': {\n",
    "            'lstm_gru': float(lstm_pred),\n",
    "            'xgboost': float(xgb_pred),\n",
    "            'arima_garch': float(arima_pred),\n",
    "            'monte_carlo': float(mc_median),\n",
    "            'ensemble': float(ensemble)\n",
    "        },\n",
    "        'change_pct': float(change),\n",
    "        'signal': signal,\n",
    "        'confidence_intervals': confidence_intervals,\n",
    "        'risk_metrics': risk_metrics\n",
    "    }\n",
    "    \n",
    "    with open('latest_prediction.json', 'w') as f:\n",
    "        json.dump(latest_pred, f, indent=2)\n",
    "    print(f\"✅ Latest prediction saved to: latest_prediction.json\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PREDICTION COMPLETE!\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\n❌ Model files not found. Please check the path: {model_path}\")\n",
    "    print(f\"Error: {str(e)}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1a2941-9b83-49eb-860a-9283bd22d29c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015d3d86-fcbe-4f3c-afb3-08bebc037620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TensorFlow 2.10)",
   "language": "python",
   "name": "tf-2.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
